{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306da614",
   "metadata": {},
   "source": [
    "# Create args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45e5710-356e-4d26-80b2-e5011d5c81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os \n",
    "class Args(argparse.Namespace):\n",
    "    # data=\"/scratch/guest187/Data/val_SSA\"\n",
    "    data = \"/scratch/guest187/Data/val_SSA/monai\"\n",
    "    preproc_set=\"val\"\n",
    "    data_used=\"SSA\"\n",
    "    results='/scratch/guest187/Data/val_SSA/results'\n",
    "    optimiser=\"adam\"\n",
    "    criterion=\"dice\"\n",
    "    exec_mode=\"predict\"\n",
    "    seed=42\n",
    "    batch_size=4\n",
    "    val_batch_size=2\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c9b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/home/guest187/GitRepo_Brats23/UNN_BraTS23/scripts')\n",
    "import modelZoo_monai as mZoo\n",
    "import data_loader as dl\n",
    "from monai_functions import (\n",
    "    save_checkpoint,\n",
    "    define_model,\n",
    "    define_dataloaders,\n",
    "    model_params,\n",
    "    val_params,\n",
    "    train)\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84183f85",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d13677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "global_step\n",
      "pytorch-lightning_version\n",
      "state_dict\n",
      "loops\n",
      "callbacks\n",
      "optimizer_states\n",
      "lr_schedulers\n",
      "NativeMixedPrecisionPlugin\n",
      "hparams_name\n",
      "hyper_parameters\n"
     ]
    }
   ],
   "source": [
    "pth = '/scratch/guest187/Data/train_gli_hack/results_hack_finetune_ssa/checkpoints/f0_finetune/epoch=39-dice=91.38.ckpt'\n",
    "# pth = '/scratch/guest187/Data/train_all/results/test_fullRunThrough/best_metric_model_fullTest.pth'\n",
    "checkpoint = torch.load(pth, map_location=torch.device('cpu'))\n",
    "keys = checkpoint.keys()\n",
    "\n",
    "for key in checkpoint.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f9f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "state_dict = checkpoint[\"state_dict\"]\n",
    "print(type(state_dict))\n",
    "\n",
    "state_dict2 = dict(state_dict)\n",
    "print(type(state_dict2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fa3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patch_size': [128, 128, 128], 'spacings': [1.0, 1.0, 1.0], 'n_class': 4, 'in_channels': 5}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "cnfgP = '/scratch/guest187/Data/train_all_nnUNET/train_all_data/results/11_3d/config.pkl'\n",
    "config = pickle.load(open(cnfgP, \"rb\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004dae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
      "[[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n"
     ]
    }
   ],
   "source": [
    "patch_size, spacings = config[\"patch_size\"], config[\"spacings\"]\n",
    "strides, kernels, sizes = [], [], patch_size[:]\n",
    "while True:\n",
    "    spacing_ratio = [spacing / min(spacings) for spacing in spacings]\n",
    "    stride = [\n",
    "        2 if ratio <= 2 and size >= 2 * 2 else 1 for (ratio, size) in zip(spacing_ratio, sizes)\n",
    "    ]\n",
    "    kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "    if all(s == 1 for s in stride):\n",
    "        break\n",
    "    sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "    spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "    kernels.append(kernel)\n",
    "    strides.append(stride)\n",
    "    if len(strides) == 6:\n",
    "        break\n",
    "strides.insert(0, len(spacings) * [1])\n",
    "kernels.append(len(spacings) * [3])\n",
    "\n",
    "print(strides)\n",
    "print(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bbe44",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7652c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inference method\n",
    "from monai.inferers import sliding_window_inference\n",
    "def inference(VAL_AMP, model, input):\n",
    "    def _compute(input):\n",
    "        '''\n",
    "        roi_size â€“ the spatial window size for inferences. \n",
    "        When its components have None or non-positives, the corresponding inputs dimension will be used. \n",
    "        if the components of the roi_size are non-positive values, the transform will use the corresponding components of img size.\n",
    "        For example, roi_size=(32, -1) will be adapted to (32, 64) if the second spatial dimension size of img is 64\n",
    "        '''\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=None,\n",
    "            sw_batch_size=4, #sw_batch_size denotes the max number of windows per network inference iteration, not the batch size of inputs.\n",
    "            predictor=model,\n",
    "            overlap=0.2,\n",
    "            mode='constant'\n",
    "        )\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8975d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00129-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00169-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00192-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00143-000', '/scratch/guest187/Data/val_SSA/monai/dataset.json', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00126-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00227-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00139-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00148-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00218-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00188-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00210-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00198-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00132-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00158-000', '/scratch/guest187/Data/val_SSA/monai/BraTS-SSA-00180-000']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight\". \n\tUnexpected key(s) in state_dict: \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight\". \n\tsize mismatch for model.0.conv.weight: copying a param with shape torch.Size([16, 4, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 4, 3, 3, 3]).\n\tsize mismatch for model.0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 64, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for model.1.submodule.1.submodule.0.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 96, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.0.conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.0.conv.weight: copying a param with shape torch.Size([128, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 128, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.0.conv.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.2.conv.weight: copying a param with shape torch.Size([384, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 128, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.2.conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.1.submodule.1.submodule.2.conv.weight: copying a param with shape torch.Size([128, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 96, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.2.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for model.1.submodule.2.conv.weight: copying a param with shape torch.Size([64, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 64, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.2.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.2.conv.weight: copying a param with shape torch.Size([32, 4, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# checkpoint to test: finetuned hackathon model brats21\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# checkpoint = '/scratch/guest187/Data/train_gli_hack/results_hack_finetune_ssa/checkpoints/f0_finetune/epoch=39-dice=91.38.ckpt'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m checkpoint2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/guest187/Data/train_all/results/test_fullRunThrough/best_metric_model_fullTest.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model, n_channels \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load validation data to dataloader\u001b[39;00m\n\u001b[1;32m     11\u001b[0m data_transforms \u001b[38;5;241m=\u001b[39m dl\u001b[38;5;241m.\u001b[39mdefine_transforms(n_channels)\n",
      "File \u001b[0;32m~/GitRepo_Brats23/UNN_BraTS23/scripts/monai_functions.py:106\u001b[0m, in \u001b[0;36mdefine_model\u001b[0;34m(checkpoint)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint)\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# sdict = dict(ckpt[\"state_dict\"])\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# model.load_state_dict(sdict, strict=False)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, n_channels\n",
      "File \u001b[0;32m~/hackathon/lib/python3.9/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight\". \n\tUnexpected key(s) in state_dict: \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight\". \n\tsize mismatch for model.0.conv.weight: copying a param with shape torch.Size([16, 4, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 4, 3, 3, 3]).\n\tsize mismatch for model.0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 64, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for model.1.submodule.1.submodule.0.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 96, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.0.conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.0.conv.weight: copying a param with shape torch.Size([128, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 128, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.0.conv.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.2.conv.weight: copying a param with shape torch.Size([384, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 128, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.1.submodule.2.conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for model.1.submodule.1.submodule.2.conv.weight: copying a param with shape torch.Size([128, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 96, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.1.submodule.2.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for model.1.submodule.2.conv.weight: copying a param with shape torch.Size([64, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 64, 3, 3, 3]).\n\tsize mismatch for model.1.submodule.2.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.2.conv.weight: copying a param with shape torch.Size([32, 4, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3, 3])."
     ]
    }
   ],
   "source": [
    "validation_dir=args.data\n",
    "validation_files = [os.path.join(validation_dir, file) for file in os.listdir(validation_dir)]\n",
    "print(validation_files)\n",
    "# checkpoint to test: finetuned hackathon model brats21\n",
    "# checkpoint = '/scratch/guest187/Data/train_gli_hack/results_hack_finetune_ssa/checkpoints/f0_finetune/epoch=39-dice=91.38.ckpt'\n",
    "checkpoint2 = '/scratch/guest187/Data/train_all/results/test_fullRunThrough/best_metric_model_fullTest.pth'\n",
    "\n",
    "model, n_channels = define_model(checkpoint2)\n",
    "\n",
    "# Load validation data to dataloader\n",
    "data_transforms = dl.define_transforms(n_channels)\n",
    "dataloader = dl.load_data(args, data_transforms)\n",
    "\n",
    "val_loader = dataloader['val']\n",
    "\n",
    "# Validation parameters\n",
    "VAL_AMP, dice_metric, dice_metric_batch, post_transforms = val_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1b864-0ff7-4687-99a8-d0b7506853ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d204f8-862b-4f8a-b6ff-d3eefc989b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(val_loader):\n",
    "    val_inputs = batch[0].to(device)------------------------------------\n",
    "    print(val_inputs.shape)----------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5309d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, n_channels = define_model(checkpoint)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    for step, batch in enumerate(val_loader):\n",
    "        val_input = batch[0].to(device)\n",
    "        # print(val_input.shape)\n",
    "        val_output = inference(VAL_AMP, model, val_input)\n",
    "        val_output = post_transforms(val_output[0])\n",
    "        plt.figure(\"image\", (24, 6))\n",
    "        for i in range(4):\n",
    "            plt.subplot(1, 4, i + 1)\n",
    "            plt.title(f\"image channel {i}\")\n",
    "            plt.imshow(validation_dataset[6][\"image\"][i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "        # visualize the 3 channels label corresponding to this image\n",
    "        plt.figure(\"label\", (18, 6))\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.title(f\"label channel {i}\")\n",
    "            plt.imshow(validation_dataset[6][\"label\"][i, :, :, 70].detach().cpu())\n",
    "        plt.show()\n",
    "        # visualize the 3 channels model output corresponding to this image\n",
    "        plt.figure(\"output\", (18, 6))\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.title(f\"output channel {i}\")\n",
    "            plt.imshow(val_output[i, :, :, 70].detach().cpu())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34703946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5642b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
