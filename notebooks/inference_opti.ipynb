{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306da614",
   "metadata": {},
   "source": [
    "# Create args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561262cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os \n",
    "class Args(argparse.Namespace):\n",
    "    data=\"/scratch/guest187/Data/val_ssa/12_3d\"\n",
    "    preproc_set=\"val\"\n",
    "    data_used=\"SSA\"\n",
    "    results='/scratch/guest187/Results/train_ssa/ssa_split48/predictions_testing'\n",
    "    exec_mode=\"predict\"\n",
    "    seed=42\n",
    "    batch_size=4\n",
    "    val_batch_size=2\n",
    "    ckpt_path='/scratch/guest187/Results/train_ssa/ssa_split48/results/training48/f3/epoch=138-dice=90.01.ckpt'\n",
    "    # model=\"brats22\" #\"unet\"\n",
    "    nfolds=1\n",
    "    gpus=1 \n",
    "    amp=True\n",
    "    save_preds=True \n",
    "    brats=True\n",
    "    brats22_model=True\n",
    "    tta=True\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14f9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e73a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c9b15c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtio\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnibabel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnib\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglob\u001b[39;00m \u001b[39mimport\u001b[39;00m glob\n",
      "File \u001b[1;32mc:\\Users\\amoda\\anaconda3\\lib\\site-packages\\torchio\\__init__.py:8\u001b[0m\n\u001b[0;32m      4\u001b[0m __email__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfepegar@gmail.com\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m0.18.92\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amoda\\anaconda3\\lib\\site-packages\\torchio\\utils.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Union\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnibabel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnib\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mSimpleITK\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msitk\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amoda\\anaconda3\\lib\\site-packages\\nibabel\\__init__.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m spm2analyze \u001b[39mas\u001b[39;00m spm2\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m spm99analyze \u001b[39mas\u001b[39;00m spm99\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m streamlines, viewers\n\u001b[0;32m     48\u001b[0m \u001b[39m# isort: split\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[39m# object imports\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39manalyze\u001b[39;00m \u001b[39mimport\u001b[39;00m AnalyzeHeader, AnalyzeImage\n",
      "File \u001b[1;32mc:\\Users\\amoda\\anaconda3\\lib\\site-packages\\nibabel\\streamlines\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtractogram\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyTractogram, Tractogram\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtractogram_file\u001b[39;00m \u001b[39mimport\u001b[39;00m ExtensionWarning\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrk\u001b[39;00m \u001b[39mimport\u001b[39;00m TrkFile\n\u001b[0;32m     13\u001b[0m \u001b[39m# List of all supported formats\u001b[39;00m\n\u001b[0;32m     14\u001b[0m FORMATS \u001b[39m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m.trk\u001b[39m\u001b[39m'\u001b[39m: TrkFile,\n\u001b[0;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m.tck\u001b[39m\u001b[39m'\u001b[39m: TckFile,\n\u001b[0;32m     17\u001b[0m }\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:971\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1539\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:156\u001b[0m, in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:148\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/home/guest187/GitRepo_Brats23/nnUnet')\n",
    "import subprocess\n",
    "try:\n",
    "    import os\n",
    "    import numpy as np \n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import torchio as tio\n",
    "    import nibabel as nib\n",
    "    from glob import glob\n",
    "    from subprocess import call\n",
    "    from scipy.ndimage import label\n",
    "    from monai.inferers import sliding_window_inference\n",
    "    from nnunet.brats22_model import UNet3D\n",
    "    \n",
    "    \n",
    "except ModuleNotFoundError as e:\n",
    "    package = str(e).split(\"'\")[0]\n",
    "    subprocess.run(['pip', 'install', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7872d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "# sys.path.append('/Users/alexandrasmith/Desktop/Workspace/Projects/UNN_BraTS23/scripts')\n",
    "sys.path.append('C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\UNN_BraTS23\\\\scripts')\n",
    "import subprocess\n",
    "try:\n",
    "    import os\n",
    "    import numpy as np \n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import torchio as tio\n",
    "    import nibabel as nib\n",
    "    from glob import glob\n",
    "    from subprocess import call\n",
    "    from scipy.ndimage import label\n",
    "    from monai.inferers import sliding_window_inference\n",
    "    import modelZoo_monai as mZoo\n",
    "    import data_loader as dl\n",
    "    from monai_functions import (\n",
    "        save_checkpoint,\n",
    "        define_model,\n",
    "        define_dataloaders,\n",
    "        model_params,\n",
    "        val_params,\n",
    "        train)\n",
    "    \n",
    "except ModuleNotFoundError as e:\n",
    "    package = str(e).split(\"'\")[0]\n",
    "    subprocess.run(['pip', 'install', package])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84183f85",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d13677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = '/scratch/guest187/Data/train_gli_hack/results_hack_finetune_ssa/checkpoints/f0_finetune/epoch=39-dice=91.38.ckpt'\n",
    "# pth = '/scratch/guest187/Data/train_all/results/test_fullRunThrough/best_metric_model_fullTest.pth'\n",
    "checkpoint = torch.load(pth)\n",
    "keys = checkpoint.keys()\n",
    "\n",
    "for key in checkpoint.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint[\"state_dict\"]\n",
    "print(type(state_dict))\n",
    "\n",
    "state_dict2 = dict(state_dict)\n",
    "print(type(state_dict2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cnfgP = '/scratch/guest187/Data/train_all_nnUNET/train_all_data/results/11_3d/config.pkl'\n",
    "config = pickle.load(open(cnfgP, \"rb\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004dae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, spacings = config[\"patch_size\"], config[\"spacings\"]\n",
    "strides, kernels, sizes = [], [], patch_size[:]\n",
    "while True:\n",
    "    spacing_ratio = [spacing / min(spacings) for spacing in spacings]\n",
    "    stride = [\n",
    "        2 if ratio <= 2 and size >= 2 * 2 else 1 for (ratio, size) in zip(spacing_ratio, sizes)\n",
    "    ]\n",
    "    kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "    if all(s == 1 for s in stride):\n",
    "        break\n",
    "    sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "    spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "    kernels.append(kernel)\n",
    "    strides.append(stride)\n",
    "    if len(strides) == 6:\n",
    "        break\n",
    "strides.insert(0, len(spacings) * [1])\n",
    "kernels.append(len(spacings) * [3])\n",
    "\n",
    "print(strides)\n",
    "print(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bbe44",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7652c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inference method\n",
    "def inference(VAL_AMP, model, input):\n",
    "    def _compute(input):\n",
    "        '''\n",
    "        roi_size â€“ the spatial window size for inferences. \n",
    "        When its components have None or non-positives, the corresponding inputs dimension will be used. \n",
    "        if the components of the roi_size are non-positive values, the transform will use the corresponding components of img size.\n",
    "        For example, roi_size=(32, -1) will be adapted to (32, 64) if the second spatial dimension size of img is 64\n",
    "        '''\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=None,\n",
    "            sw_batch_size=4, #sw_batch_size denotes the max number of windows per network inference iteration, not the batch size of inputs.\n",
    "            predictor=model,\n",
    "            overlap=0.2,\n",
    "            mode='constant'\n",
    "        )\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "def infer():\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            input = batch[0]\n",
    "            # case = str(batch[1]).split('/')[-1].replace(\"-stk.npy',)\", \"\")\n",
    "            case = str(batch[1]).split('\\\\')[-1].replace(\"-stk.npy',)\", \"\")\n",
    "            print(f\"Working on subject: {case}; shape size is: {input.shape}\")\n",
    "            #Run inference\n",
    "            output = inference(VAL_AMP, model, input)\n",
    "            print(f\"Output before post_transforms is: {output.shape}\")\n",
    "            val_output = post_transforms(output[0])\n",
    "            print(f\"Output after post_transforms is: {val_output.shape}\")\n",
    "\n",
    "            #Attempt to convert and save to numpy for post processing\n",
    "            val_output2 = val_output.cpu().numpy()\n",
    "            val_out_pth = os.path.join(args.results, f\"{case}_preds.npy\")\n",
    "            try:\n",
    "                print(f\"trying to save to numpy file, with shape: {val_output2.shape}\")\n",
    "                np.save(val_out_pth, val_output2)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the file: {e}\")\n",
    "\n",
    "# Save to nifti\n",
    "def save_nifti(final_np, img, outfile):\n",
    "    '''\n",
    "    Save numpy to NIfTI format\n",
    "    input numpy must have 3 dimensions only\n",
    "    '''\n",
    "    \n",
    "    img = nib.load(img) ## load original image from path\n",
    "    nib.save(\n",
    "        nib.Nifti1Image(final_np, img.affine, header=img.header),\n",
    "        outfile\n",
    "    )\n",
    "\n",
    "def save_final_preds(pred, img, outfile, fname):\n",
    "    #convert tensor to tio subject for padding and affine alignment\n",
    "    predT = torch.from_numpy(pred).unsqueeze(0)\n",
    "    subject = tio.Subject(\n",
    "            image=tio.ScalarImage(tensor=predT),\n",
    "            name=fname\n",
    "            )\n",
    "    tranformed_subject = tio.CropOrPad((240, 240, 155))\n",
    "    tranformed_subject = tranformed_subject(subject)\n",
    "    pred_final = tranformed_subject[\"image\"].data.numpy().squeeze(0)\n",
    "    print(f\"Shape chanes: initial = {pred.shape}, tensor = {predT.shape}, and final npy = {pred_final.shape}\")\n",
    "\n",
    "    save_nifti(pred_final, img, outfile)\n",
    "\n",
    "\n",
    "#------------ OPTINET -----##\n",
    "def to_lbl(pred):\n",
    "    print(\"in to_lbl: \", pred.shape)\n",
    "    print(pred.shape)\n",
    "    print(pred[0].shape, pred[1].shape, pred[2].shape)\n",
    "# labels_dict = {\"0\": \"background\", \"1\": \"edema\", \"2\": \"non-enhancing tumor\", \"3\": \"enhancing tumour\"}\n",
    "\n",
    "# # The segementation volume contains values [0, 1, 2, 3]. As per BraTS summarizing paper for 2023, annotations comprise the \n",
    "# - 1 for NCR (necrotic tumor core)\n",
    "# - 2 for ED (peritumoral edematous/invaded tissue)\n",
    "# - 3 for ET (GD-enhancing tumor)\n",
    "# - 0 for everything else\n",
    "\n",
    "    enh = pred[2]\n",
    "    print(enh.shape)\n",
    "    pad = pred == 0.5\n",
    "    pred[pad==True] = 0\n",
    "\n",
    "    c1, c2, c3 = pred[0] > 0.4, pred[1] > 0.35, pred[2] > 0.375\n",
    "    print(\"CShapes: \", c1.shape, c2.shape, c3.shape)\n",
    "    # print(set(pred.flatten()))\n",
    "    print(\"before assignment:\" ,pred.shape)\n",
    "\n",
    "    # print(set(pred.flatten()))\n",
    "    pred = (c1 > 0).astype(np.uint8)\n",
    "    # print(set(pred.flatten()))\n",
    "        #  assigns 0 to elements in pred where c1 is False and 1 where c1 is True, effectively converting c1 to 0s and 1s in pred\n",
    "            ## if the WT probability for a given voxel is less than 0.45 then its class is set to 0 (background) or its assigned to NCR\n",
    "\n",
    "    pred[(c2 == False) * (c1 == True)] = 2 #AA changed to 1\n",
    "    # print(set(pred.flatten()))\n",
    "        # This step assigns 2 to regions where c2 is False and c1 is True, which might indicate a region that extends beyond the threshold of c1 and is within the threshold of c2.\n",
    "            # otherwise if the probability for TC is less than 0.4 the voxel class is 2 (ED) (wherever NCR was assigned in C1 as 1, if TC is false at that point, then class is oedema)\n",
    "\n",
    "    pred[(c3 == True) * (c1 == True)] = 3\n",
    "    # print(set(pred.flatten()))\n",
    "        # assigns 3 to regions where c3 is True and c1 is True, which might indicate a region that is within the threshold of both c1 and c3.\n",
    "        # finally if probability for ET is less than 0.4 voxel has class 1 (NCR), or otherwise 4 (ET).\n",
    "\n",
    "    print(\"after assignment: \", pred.shape)\n",
    "\n",
    "\n",
    "    components, n = label(pred == 3)\n",
    "    for et_idx in range(1, n + 1):\n",
    "        _, counts = np.unique(pred[components == et_idx], return_counts=True)\n",
    "        if 1 < counts[0] and counts[0] < 4 and np.mean(enh[components == et_idx]) < 0.9:\n",
    "            pred[components == et_idx] = 1\n",
    "    print(\"after for loop: \", pred.shape)\n",
    "    \n",
    "    et = pred == 3\n",
    "    if 0 < et.sum() and et.sum() < 5 and np.mean(enh[et]) < 0.9:\n",
    "        pred[et] = 1\n",
    "    print(\"before _lbl return: \", pred.shape)\n",
    "\n",
    "    pred = np.transpose(pred, (2, 1, 0)).astype(np.uint8)\n",
    "    print(\"after transpose: \", pred.shape)\n",
    "    return pred\n",
    "\n",
    "def prepare_preditions(e):\n",
    "    fname = e.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    # fname = e.split(\"\\\\\")[-1].split(\".\")[0][:-6]\n",
    "    print(fname)\n",
    "    # CALL BELOW LINE FOR POST PROCESSING with ensembling\n",
    "    # preds = [np.load(f) for f in e]\n",
    "    # print(preds)\n",
    "    # p = to_lbl(np.mean(preds, 0))\n",
    "\n",
    "    # ELSE JUST SAVE NP MEANS ALONG AXIS 0\n",
    "    pred = np.load(e)\n",
    "    # print(pred.shape)\n",
    "\n",
    "    p = to_lbl(pred)\n",
    "    print(p.shape)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8975d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir=args.data\n",
    "validation_files = [os.path.join(validation_dir, file) for file in os.listdir(validation_dir)]\n",
    "print('\\n'.join(validation_files))\n",
    "\n",
    "model, n_channels = define_model(args.ckpt_path)\n",
    "\n",
    "# Load validation data to dataloader\n",
    "data_transforms = dl.define_transforms(n_channels)\n",
    "dataloader = dl.load_data(args, data_transforms)\n",
    "\n",
    "val_loader = dataloader['val']\n",
    "\n",
    "# Validation parameters\n",
    "VAL_AMP, dice_metric, dice_metric_batch, post_transforms = val_params()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "infer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d204f8-862b-4f8a-b6ff-d3eefc989b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = 15\n",
    "for step, batch in enumerate(val_loader):\n",
    "    if step < max_idx:\n",
    "        input = batch[0]\n",
    "        print(input.shape)\n",
    "        print(str(batch[1]).split('/')[-1].replace(\"-stk_x.npy',)\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4ea38-8b46-4e82-8fde-7ff017520674",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = 15\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(val_loader):\n",
    "        if step < max_idx:\n",
    "            input = batch[0].to(device)\n",
    "            case = str(batch[1]).split('/')[-1].replace(\"-stk_x.npy',)\", \"\")\n",
    "            print(input.shape)\n",
    "            output = inference(VAL_AMP, model, input)\n",
    "            print(output.shape)\n",
    "            val_output = post_transforms(output[0])\n",
    "            print(val_output.shape)\n",
    "            \n",
    "            val_output2 = val_output.cpu().numpy()\n",
    "            print(type(val_output2))\n",
    "\n",
    "            val_out_pth = os.path.join(args.results, f\"{case}_preds.npy\")\n",
    "            print(type(val_out_pth))\n",
    "            try:\n",
    "                np.save(val_out_pth, val_output2)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the file: {e}\")\n",
    "            # visualize the 3 channels model output corresponding to this image\n",
    "            plt.figure(\"model output\", (18, 6))\n",
    "            for i in range(3):\n",
    "                plt.subplot(1, 3, i + 1)\n",
    "                plt.title(f\"{case}: output channel {i}\")\n",
    "                plt.imshow(val_output2[i, :, :, 30])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34703946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de735090-e8ea-4ed5-bde3-a4f517604124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[['C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00126-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00129-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00132-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00139-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00143-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00148-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00158-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00169-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00180-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00188-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00192-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00198-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00210-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00218-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00227-000.npy']]\n",
      "Preparing final predictions\n",
      "['C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00126-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00129-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00132-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00139-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00143-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00148-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00158-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00169-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00180-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00188-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00192-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00198-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00210-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00218-000.npy', 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions_epoch=98-dice=95_04_task=01_fold=0_tta\\\\BraTS-SSA-00227-000.npy']\n",
      "BraTS-SSA-00126-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00129-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00132-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00139-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00143-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00148-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00158-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00169-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00180-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00188-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00192-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00198-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00210-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00218-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "BraTS-SSA-00227-000\n",
      "in to_lbl:  (3, 155, 240, 240)\n",
      "(3, 155, 240, 240)\n",
      "(155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "(155, 240, 240)\n",
      "CShapes:  (155, 240, 240) (155, 240, 240) (155, 240, 240)\n",
      "before assignment: (3, 155, 240, 240)\n",
      "after assignment:  (155, 240, 240)\n",
      "after for loop:  (155, 240, 240)\n",
      "before _lbl return:  (155, 240, 240)\n",
      "after transpose:  (240, 240, 155)\n",
      "(240, 240, 155)\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "results = 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\'\n",
    "try:\n",
    "    os.makedirs(os.path.join(results, \"final_preds\"))\n",
    "except:\n",
    "    print(\"directory exists\")\n",
    "\n",
    "#--------------MONAI\n",
    "# examples = sorted(glob('C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\npy\\\\*'))\n",
    "# orig_data = 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\SSA_Val'\n",
    "orig_data = 'C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\CC\\\\Backup_2407\\\\val_SSA\\\\monai'\n",
    "print(os.path.exists(orig_data))\n",
    "\n",
    "#------------- OPTINET     \n",
    "preds = sorted(glob('C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\train_gli\\\\ftSSA_f0\\\\predictions*'))\n",
    "# examples = list(zip(*[sorted(glob(f\"{p}\\\\*.npy\")) for p in preds]))\n",
    "examples = [sorted(glob(f\"{p}\\\\*.npy\")) for p in preds]\n",
    "print(examples)\n",
    "\n",
    "print(\"Preparing final predictions\")\n",
    "for e in examples:\n",
    "    print(e)\n",
    "    for pnpy in e:\n",
    "        pred = prepare_preditions(pnpy)\n",
    "        fname = pnpy.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        # # fname = e.split(\"\\\\\")[-1].split(\".\")[0][:-6]\n",
    "        # # print(pred.shape)\n",
    "        outfile = os.path.join(results,\"final_preds\", f\"{fname}.nii.gz\")\n",
    "        img = os.path.join(orig_data, fname, f\"{fname}-t1n.nii.gz\")\n",
    "        img_load = nib.load(img)\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(pred, img_load.affine, header=img_load.header),\n",
    "        outfile\n",
    "        )\n",
    "    # save_final_preds(pred, img, outfile, fname)\n",
    "    \n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nib.load(os.path.join (args.results, \"BraTS-SSA-00132-000.nii.gz\"))\n",
    "print(sample.shape)\n",
    "\n",
    "print(set(np.array(sample.dataobj).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8beaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_chk = np.load('C:\\\\Users\\\\amoda\\\\Documents\\\\SPARK\\\\BraTS2023\\\\results\\\\preds_allFolds\\\\predictions_epoch=128-dice=93_74_task=01_fold=3_tta\\\\BraTS-SSA-00143-000.npy')\n",
    "\n",
    "print(\"Brain background: \", lbl_chk[:,70,89,76])\n",
    "print(\"pad background: \",lbl_chk[:,70,227,216] )\n",
    "print(\"Yellow: \",lbl_chk[:,70,113,178])\n",
    "print(\"Green: \",lbl_chk[:,70,134,150])\n",
    "print(\"Red: \",lbl_chk[:,70,142,121])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "\n",
    "n, z = 5, 75\n",
    "data = sorted(glob(\"/scratch/guest187/Data/val_SSA/results/monai_test/*.nii.gz\"))\n",
    "for i in range(n):\n",
    "    fname = data[i].split(\"/\")[-1].split(\".\")[0]\n",
    "    print(fname)\n",
    "    img = nib.load(f\"/scratch/guest187/Data/val_SSA/finetune_ssa/images/{fname}-stk.nii.gz\").get_fdata().astype(np.float32)\n",
    "    pred = nib.load(data[i]).get_fdata().astype(np.uint8)[:, :, z]\n",
    "    imgs = [img[:, :, z, i] for i in [0, 3]] + [pred]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 12))\n",
    "    for i in range(3):\n",
    "        if i < 2:\n",
    "            ax[i].imshow(imgs[i], cmap='gray')\n",
    "        else:\n",
    "            ax[i].imshow(imgs[i]);\n",
    "        ax[i].axis('off')  \n",
    "    plt.tight_layout()            \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
