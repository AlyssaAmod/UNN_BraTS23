{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentations Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Here we will check what effects torchio transformations have on each volume\n",
    "1. Crop or Pad\n",
    "2. Mask - normalisation using label as a mask\n",
    "3. One Hot Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data using the data_prep code\n",
    "**NB: DO NOT RUN THE DATA PREPROC PART YET**\n",
    "\n",
    "To ensure we are just working with a few functions at a time, py script is copied in below without preproc. We will run each example on several SSA and GLI datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some functions from scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" This script is to prepare the provided data set for pre-processing and then run all pre-processing.\n",
    "It will take as input a directory path to the training data and apply the following:\n",
    "    1. Read in the dataset folder structure\n",
    "    2. Store variables\n",
    "        subjID = subject IDs\n",
    "        img_dir = path to each imaging modality\n",
    "        lbl dir = path to corresponding segmentation mask\n",
    "    3. Load nifty file for each modality\n",
    "    4. Extract voxel intensity values, header information and affine matrix\n",
    "        Stack voxel data from each modality into 1 tensor\n",
    "        cropping out background\n",
    "        Add an extra channel for one hot encoding??\n",
    "    5. Save the following files:\n",
    "        images/subjIDxxx-stk.nii.gz = stacked modalities output into a nifti file in an images folder\n",
    "        labels/subjIDxxx-lbl.nii.gz = segmentation mask\n",
    "    6. Create and save json file that contains a dictionary of dictionaries and lists:\n",
    "        A dictionary of dummy coding for seg labels as provided by BraTS\n",
    "            \"labels\" : {\"0\": \"background\", \"1\": \"edema\", \"2\": \"non-enhancing tumor\", \"3\": \"enhancing tumour\"}\n",
    "        A dictionary of dummy coding for each modality\n",
    "            \"modality\": {\"0\": \"FLAIR\", \"1\": \"T1\", \"2\": \"T1CE\", \"3\": \"T2\"}\n",
    "        A dictionary of dictionaries containing the image-label path pairs\n",
    "            \"training\": [{\"image\": \"images/subjIDxxx.nii.gz\", \"label\": \"labels/subjIDxxx_seg.nii.gz\"}\n",
    "\n",
    "Add noise defs for fake SSA data in an if \n",
    "\"\"\"\n",
    "\n",
    "## Import key libraries\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import time\n",
    "from subprocess import call\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from data_class import MRIDataset\n",
    "import utils\n",
    "from utils import get_main_args\n",
    "from utils import extract_imagedata\n",
    "from data_transforms import transforms_preproc\n",
    "from data_transforms import apply_transforms\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "def prepare_nifty(dataset):\n",
    "    \"\"\" \n",
    "    This is the main data prepartion function. \n",
    "    It extracts the the image data from each volume and then stacks all modalities into one file.\n",
    "    It then applies standard image preprocessing such as one hot encoding, realignment to RAS+ Z normalisation\n",
    "    data_loader and trainer will work with these files.\n",
    "    Input:\n",
    "        dataset class\n",
    "        args\n",
    "        # OLD: \n",
    "            path to directory containing folders of subject IDs\n",
    "            list of modalities\n",
    "    Output:\n",
    "        JSON files:]\n",
    "            subj_info == subject IDs & dir paths\n",
    "            image_info == shape & resolution data per subject per modality\n",
    "            dataset == modality keys, segmentation keys, image-label pairs per subj\n",
    "        NifTI files:.\n",
    "            subjIDxxx-stk.nii.gz == stacked nifti img data \n",
    "            subjIDxxx-lbl.nii.gz == seg mask img data\n",
    "\n",
    "    \"\"\"\n",
    "    data_dir = dataset.data_dir\n",
    "    subj_dir_pths, subj_dirs = [],[]\n",
    "    img_pth, seg_pth = dataset.img_pth, dataset.seg_pth\n",
    "\n",
    "    modalities = dataset.modalities\n",
    "    img_shapes = {}\n",
    "    res = {}\n",
    "    img_modality = []\n",
    "    ext_dict_modal = {**{f\"-{m}.nii.gz\": img_modality for m in modalities}}\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for directory in sorted(dirs, key=lambda x: x.lower(), reverse=True):\n",
    "            if not \"BraTS-\" in directory:\n",
    "                break\n",
    "            else:\n",
    "                subj_id = str(directory)\n",
    "                print(\"Working on subj: \", subj_id)\n",
    "                subj_dir_pth = os.path.join(root,directory)\n",
    "                subj_dir_pths.append(subj_dir_pth)\n",
    "                #Load and stack modalities\n",
    "                print(\"Loading and stacking modalities\")\n",
    "                img_paths = [os.path.join(subj_dir_pth, subj_id + f\"-{m}.nii.gz\") for m in modalities]\n",
    "                loaded_modalities = [nib.load(path) for path in img_paths]\n",
    "                t1n, t1c, t2w, t2f = loaded_modalities\n",
    "                img_modality.extend([t1n, t1c, t2w, t2f]) \n",
    "                affine, header = t2f.affine, t2f.header\n",
    "                res[f'{os.path.basename(root)}_RES']=header.get_zooms()\n",
    "                imgs = np.stack([extract_imagedata(modality) for modality in loaded_modalities], axis=-1)\n",
    "                shapes = {modality: imgs[..., i].shape for i, modality in enumerate(modalities)}\n",
    "                img_shapes[f'{subj_id}'] = shapes\n",
    "                print(\"Image shapes: \", img_shapes)\n",
    "                imgs = nib.nifti1.Nifti1Image(imgs, affine, header=header)\n",
    "                nib.save(imgs, os.path.join(subj_dir_pth, subj_id + \"-stk.nii.gz\"))\n",
    "                # Load and save seg\n",
    "                print(\"Loading and saving segmentation\")\n",
    "\n",
    "                seg = nib.load(os.path.join(subj_dir_pth, subj_id + \"-seg.nii.gz\"))\n",
    "                seg_affine, seg_header = seg.affine, seg.header\n",
    "                seg = extract_imagedata(seg, \"unit8\")\n",
    "                #seg[vol == 4] = 3 --> not sure what this does yet\n",
    "                seg = nib.nifti1.Nifti1Image(seg, seg_affine, header=seg_header)\n",
    "                print(\"Seg Shape\", seg.shape)\n",
    "                nib.save(seg, os.path.join(subj_dir_pth, subj_id + \"-lbl.nii.gz\"))\n",
    "               \n",
    "    # save a few bits of info into a json \n",
    "    img_info = {\n",
    "        \"img_shapes\": img_shapes,\n",
    "        \"res\": res,\n",
    "        \"img_modalitypth\": img_pth\n",
    "        }\n",
    "    print(\"Saving shape & resolution data per subject\")\n",
    "    with open(os.path.join(data_dir, 'img_info.json'), 'w') as file:\n",
    "        json.dump(img_info, os.path.join(data_dir,file), cls=NumpyEncoder)\n",
    "               \n",
    "    subj_info = {\n",
    "        \"nSubjs\" : len(data_dir),\n",
    "        \"subjIDs\" : dataset.subj_dirs,\n",
    "        \"subj_dirs\" : dataset.subj_dir_pths\n",
    "    }\n",
    "    print(\"Saving SubjIDs\")\n",
    "    with open(os.path.join(data_dir, \"subj_info.json\"), \"w\") as file:\n",
    "        json.dump(subj_info,file)\n",
    "\n",
    "\n",
    "def file_prep(dataset, dataMode, train):\n",
    "    \"\"\" \n",
    "    This an extra function to save a copy of the image data extracted from each volume.\n",
    "    data_loader and trainer do not require these data as they are stored in the original subject folders as well\n",
    "\n",
    "    Creates a json file with\n",
    "        A dictionary of dummy coding for seg labels as provided by BraTS\n",
    "            \"labels\" : {\"0\": \"background\", \"1\": \"edema\", \"2\": \"non-enhancing tumor\", \"3\": \"enhancing tumour\"}\n",
    "        A dictionary of dummy coding for each modality\n",
    "            \"modality\": {\"0\": \"FLAIR\", \"1\": \"T1\", \"2\": \"T1CE\", \"3\": \"T2\"}\n",
    "        A dictionary of dictionaries containing the image-label path pairs\n",
    "            \"training\": [{\"image\": \"images/subjIDxxx.nii.gz\", \"label\": \"labels/subjIDxxx_seg.nii.gz\"}\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = dataset.data_dir\n",
    "    modalities = dataset.modalities\n",
    "    stk, lbl = dataset.proc_imgs, dataset.proc_lbls\n",
    "    subj_dirs = dataset.subj_dirs\n",
    "    \n",
    "    stk_path, lbls_path = os.path.join(data_dir, f\"images_orig-{dataMode}\"), os.path.join(data_dir, f\"labels_orig-{dataMode}\")\n",
    "    call(f\"mkdir -p {stk_path}\", shell=True)\n",
    "    if train:\n",
    "        call(f\"mkdir -p {lbls_path}\", shell=True)\n",
    "    \n",
    "    imagesF, labelsF = [], []\n",
    "\n",
    "    file_ext_dict2 = {\n",
    "        \"-lbl.nii.gz\": labelsF,\n",
    "        \"-stk.nii.gz\": imagesF}\n",
    "\n",
    "    #for subj in subj_dirs:\n",
    "        # for i in range(dataset.len(stk)):\n",
    "        #     for j in range(dataset.len(lbl)):\n",
    "        #         if subj not in stk[i] or lbl[j]:\n",
    "        #             break\n",
    "        #         print(\"subjID = \",subj)\n",
    "        #         for root, dirs, files in os.walk(stk[i]):\n",
    "        #             for file in files:\n",
    "        #                 if os.path.isfile(os.path.join(root, file)) :\n",
    "        #                     for ext, list_to_append in file_ext_dict2.items():\n",
    "        #                         if file.endswith(ext):\n",
    "        #                         #print(file_pth)\n",
    "        #                         list_to_append.append(os.path.join(root, file))\n",
    "    for i in range(len(lbl)):\n",
    "        file = os.path.basename(lbl[i])\n",
    "        d = os.path.dirname(lbl[i])\n",
    "        labelsF.append(os.path.join(d, file))\n",
    "        call(f\"cp {lbl[i]} {lbls_path}\", shell=True)\n",
    "    for i in range(len(stk)):\n",
    "        file = os.path.basename(stk[i])\n",
    "        d = os.path.dirname(stk[i])\n",
    "        imagesF.append(os.path.join(d, file))\n",
    "        call(f\"cp {stk[i]} {stk_path}\", shell=True)\n",
    "\n",
    "    if train == \"training\":\n",
    "        key = \"training\"\n",
    "        data_pairs = [{\"image\": imgF, \"label\": lblF} for (imgF, lblF) in zip(imagesF, labelsF)]\n",
    "    else:\n",
    "        key = \"test\"\n",
    "        data_pairs = [{\"image\": imgF} for imgF in imagesF]\n",
    "\n",
    "    modality = {\"0\": \"t1n\", \"1\": \"t1c\", \"2\": \"t2w\", \"3\": \"t2f\"}\n",
    "    labels_dict = {\"0\": \"background\", \"1\": \"NCR\", \"2\": \"ED\", \"3\": \"ET\"}\n",
    "\n",
    "    # **********These path pairs are not needed for data_loader or training--> this is for incase it is needed\n",
    "    images, labels = glob(os.path.join(stk_path, \"*\")), glob(os.path.join(lbls_path, \"*\"))\n",
    "    images = sorted([img.replace(data_dir + \"/\", \"\") for img in images])\n",
    "    labels = sorted([lbl.replace(data_dir + \"/\", \"\") for lbl in labels])\n",
    "    if train == \"training\":\n",
    "        key = \"training\"\n",
    "        data_pairs_fold = [{\"image\": img, \"label\": lbl} for (img, lbl) in zip(images, labels)]\n",
    "    else:\n",
    "        key = \"test\"\n",
    "        data_pairs_fold = [{\"image\": img} for img in images]\n",
    "\n",
    "    # sAve some json files for dataloading\n",
    "    dataset = {\n",
    "        \"labels\": labels_dict,\n",
    "        \"modality\": modality,\n",
    "        key: data_pairs}\n",
    "    with open(os.path.join(data_dir, \"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "\n",
    "    datasetFold = {\n",
    "        \"labels\": labels_dict,\n",
    "        \"modality\": modality,\n",
    "        key: data_pairs_fold}\n",
    "    with open(os.path.join(data_dir, \"datasetFold.json\"), \"w\") as outfile:\n",
    "        json.dump(datasetFold, outfile)\n",
    "\n",
    "\n",
    "def preprocess_data(dataset, args, transList):\n",
    "    '''\n",
    "    Function that applies all desired preprocessing steps to an image, as well as to its \n",
    "    corresponding ground truth image.\n",
    "\n",
    "    Returns: preprocessed image (not yet converted to tensor)\n",
    "    '''\n",
    "    # img is still a list of arrays of the 4 modalities from data files\n",
    "    # mask is 3d array\n",
    "\n",
    "    # return img as list of arrays, and mask as before\n",
    "    import itertools\n",
    "\n",
    "    data_dir = dataset.data_dir\n",
    "    modalities = dataset.modalities\n",
    "    stk, lbl = dataset.proc_imgs, dataset.proc_lbls\n",
    "    subj_dirs = dataset.subj_dirs\n",
    "    \n",
    "    outpath = os.path.join(data_dir, args.data_grp + \"_prepoc\")\n",
    "    call(f\"mkdir -p {outpath}\", shell=True)\n",
    "    \n",
    "    imgs = []\n",
    "    masks = []\n",
    "    # Define the list of helper functions for the transformation pipeline\n",
    "    transform_pipeline = transforms_preproc()[1]\n",
    "    \n",
    "    for i in range(len(lbl)):\n",
    "        # file = os.path.basename(lbl[i])\n",
    "        d = os.path.dirname(lbl[i])\n",
    "        proc_img = nib.load(lbl[i])\n",
    "        proc_img = extract_imagedata(proc_img)\n",
    "        proc_img_t = torch.from_numpy(proc_img)\n",
    "        proc_img_t = torch.unsqueeze(proc_img_t, axis=0)\n",
    "        for code, trans in transform_pipeline.items():\n",
    "            if code in transList:\n",
    "                proc_img_t = trans(proc_img_t)\n",
    "        np.save(os.path.join(os.path.dirname(lbl[i]), str(d) + \"-lbl.npy\"), proc_img_t)\n",
    "        masks.append(proc_img_t)\n",
    "    for i in range(len(stk)):\n",
    "        # file = os.path.basename(stk[i])\n",
    "        d = os.path.dirname(stk[i])\n",
    "        proc_img = nib.load(stk[i])\n",
    "        proc_img = extract_imagedata(proc_img)\n",
    "        proc_img_t = torch.from_numpy(proc_img)\n",
    "        # proc_img_t = np.expand_dims(proc_img, axis=0)\n",
    "        for code, trans in transform_pipeline.items():\n",
    "            if code in transList:\n",
    "                proc_img_t = trans(proc_img_t)\n",
    "        np.save(os.path.join(os.path.dirname(stk[i]), str(d) + \"-stk.npy\"), proc_img_t)\n",
    "        imgs.append(proc_img_t)\n",
    "    \n",
    "    dataNPY = MRIDataset(data_dir, args.task, modalities=modalities)\n",
    "    img_npy = dataNPY.imgs_npy\n",
    "    mask_npy = dataNPY.lbls_npy\n",
    "    for f in range(len(img_npy)):\n",
    "        call(f\"cp {img_npy[i]} {outpath}\", shell=True)\n",
    "        call(f\"cp {mask_npy[i]} {outpath}\", shell=True)\n",
    "        \n",
    "    datasetNPY = {\n",
    "        \"img_folders\" : subj_dirs,\n",
    "        \"img_np_pth\" : img_npy,\n",
    "        \"mask_np_pth\" : mask_npy,\n",
    "        \"npy_pairPths\" : [{\"image\": img, \"label\": lbl} for (img, lbl) in zip(img_npy, mask_npy)]\n",
    "    }\n",
    "    with open(os.path.join(data_dir, \"dataset.json\"), \"a\") as outfile:\n",
    "        json.dump(datasetNPY, outfile)\n",
    "\n",
    "    return imgs, masks\n",
    "\n",
    "def main():\n",
    "\n",
    "    modalities = [\"t1c\", \"t1n\", \"t2w\", \"t2f\"]\n",
    "    data_dir = '/scratch/guest187/BraTS_Africa_data/SSA_TrainingData/'\n",
    "    task = args.task\n",
    "      \n",
    "    print(\"Generating stacked nifti files.\")\n",
    "    startT = time.time()\n",
    "    origData = MRIDataset(data_dir, task, modalities=modalities)\n",
    "    prepare_nifty(origData)\n",
    "    \n",
    "    print(\"Loaded all nifti files and saved image data \\nSaving a copy to images and labels folders\")\n",
    "    train = args.preproc_set\n",
    "    prepData = MRIDataset(data_dir, task, modalities=modalities)\n",
    "    file_prep(prepData, args.data_grp, train)\n",
    "    endT = time.time()\n",
    "    print(f\"Image - label pairs created. Total time taken: {(endT - startT):.2f}\")\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
